import logging
from telegram import Update
from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters
import openai

from tokens import OPENAI_API_KEY, TELEGRAM_BOT_API_TOKEN

# Set up the OpenAI API key
openai.api_key = OPENAI_API_KEY
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

chats = {}


class Chat:
    def __init__(self, user_id):
        self.user_id = user_id
        self.messages = []
        self.questions_counter = 0


async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    chat = Chat(chat_id)
    chats[chat_id] = chat

    await context.bot.send_message(chat_id=update.effective_chat.id,
                                   text="–ü—Ä–∏–≤—ñ—Ç! –Ø Stroom Bot, —ñ —è —Ö–æ—á—É –∑–∞—Ä—è–¥–∏—Ç–∏ —Ç–µ–±–µ –Ω–∞ –≤–∏–±—ñ—Ä –Ω–∞–π–∫—Ä–∞—â–æ—ó –ø—Ä–æ—Ñ–µ—Å—ñ—ó ‚ö°Ô∏è\n"
                                        "–î–ª—è –ø–æ—á–∞—Ç–∫—É, —è —Ö–æ—á—É –ø–æ–ø—Ä–æ—Å–∏—Ç–∏ —Ç–µ–±–µ —Ä–æ–∑–ø–æ–≤—ñ—Å—Ç–∏ —â–æ—Å—å –ø—Ä–æ —Å–µ–±–µ, —â–æ–± —è –º—ñ–≥ –¥—ñ–∑–Ω–∞—Ç–∏—Å—è –ø—Ä–æ —Ç–≤–æ—ó —ñ–Ω—Ç–µ—Ä–µ—Å–∏ —Ç–∞ –∑–∞–ø—Ä–æ–ø–æ–Ω—É–≤–∞—Ç–∏ —Ç—ñ –ø—Ä–æ—Ñ–µ—Å—ñ—ó, —è–∫–∞ —ó–º –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î.\n\n"
                                        "–¢–∏ –º–æ–∂–µ—à —Ä–æ–∑–ø–æ–≤—ñ–¥–∞—Ç–∏ —â–æ –∑–∞–≤–≥–æ–¥–Ω–æ:\n"
                                        "- –Ø–∫—ñ –ø—Ä–µ–¥–º–µ—Ç–∏ —É —à–∫–æ–ª—ñ —Ç–æ–±—ñ –Ω–∞–π–±—ñ–ª—å—à–µ –ø–æ–¥–æ–±–∞—é—Ç—å—Å—è —ñ —á–æ–º—É?\n"
                                        "- –ß–∏–º —Ç–∏ –ª—é–±–∏—à –∑–∞–π–º–∞—Ç–∏—Å—è —É –≤—ñ–ª—å–Ω–∏–π —á–∞—Å?\n"
                                        "- –Ø–∫—ñ —Ç–∞–ª–∞–Ω—Ç–∏ —Ç–∏ –≤ —Å–æ–±—ñ –ø–æ–º—ñ—á–∞—î—à?\n"
                                        "- –Ø–∫—ñ –Ω–∞–≤–∏—á–∫–∏ —á–∏ –∑–¥—ñ–±–Ω–æ—Å—Ç—ñ –≤ —Ç–µ–±–µ —Ä–æ–∑–≤–∏–Ω–µ–Ω—ñ –Ω–∞–π–∫—Ä–∞—â–µ?\n"
                                        "- –Ø–∫—ñ –ø—Ä–æ–±–ª–µ–º–∏ –≤ —Å–≤—ñ—Ç—ñ —Ç–æ–±—ñ —Ö–æ—Ç—ñ–ª–æ—Å—è –± –¥–æ–ø–æ–º–æ–≥—Ç–∏ –≤–∏—Ä—ñ—à–∏—Ç–∏ —Å–≤–æ—ó–º–∏ –º–∞–π–±—É—Ç–Ω—ñ–º–∏ –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∏–º–∏ –Ω–∞–≤–∏—á–∫–∞–º–∏?\n"
                                        "- –Ø–∫—ñ —Ç–≤–æ—ó —É–ª—é–±–ª–µ–Ω—ñ –∫–Ω–∏–≥–∏, —Ñ—ñ–ª—å–º–∏, –º—É–∑–∏–∫–∞, —ñ–≥—Ä–∏ –∞–±–æ —ñ–Ω—à—ñ —Ç–≤–æ—Ä–∏ –º–∏—Å—Ç–µ—Ü—Ç–≤–∞?\n\n"
                                        "–ê–ª–µ –Ω–µ –æ–±–æ–≤'—è–∑–∫–æ–≤–æ –æ–±–º–µ–∂—É–≤–∞—Ç–∏ —Ü–∏–º–∏ –ø–∏—Ç–∞–Ω–Ω—è–º–∏. –ú–µ–Ω—ñ –¥—É–∂–µ —Ü—ñ–∫–∞–≤–æ –ø–æ–∑–Ω–∞–π–æ–º–∏—Ç–∏—Å—è "
                                        "–∑ —Ç–æ–±–æ—é, —Ç–æ–º—É —Ä–æ–∑–ø–æ–≤—ñ–¥–∞–π!")


async def listen_story_gpt(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    chat = chats[chat_id]
    print(f"chat.questions_counter: {chat.questions_counter}")

    if chat.questions_counter == 2:
        # vacancy_recommendation_message = stas_machine.get_vacancy_recommendation(chat.messages)
        chat.messages += [
            {
                "role": "user",
                "content": update.message.text,
            },
            {
                "role": "system",
                "content": "–ù–∞–¥–∞–π –ø—Ä–æ–ø–æ–∑–∏—Ü—ñ—ó —Ä–æ–±–æ—Ç–∏ –±–∞–∑—É—é—á–∏—Å—å –Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—è—Ö."
            },
        ]
        response = openai.chat.completions.create(model="gpt-4o-mini", messages=chat.messages)
        response_dict = response.to_dict()
        vacancy_recommendation_message = response_dict['choices'][0]['message']['content']
        print(vacancy_recommendation_message)
        await context.bot.send_message(chat_id=chat_id,
                                       text="–î—è–∫—É—é –∑–∞ —Ä–æ–∑–ø–æ–≤—ñ–¥—å! –¢–µ–ø–µ—Ä —è –¥–∞–º —Ç–æ–±—ñ –ø–æ—Ä–∞–¥—É —â–æ–¥–æ –≤–∏–±–æ—Ä—É –ø—Ä–æ—Ñ–µ—Å—ñ—ó üåü")
        await context.bot.send_message(chat_id=chat_id,
                                       text=vacancy_recommendation_message)
        return

    if chat.questions_counter == 0:
        initial_message = {
                "role": "system",
                "content": "–¢–∏ –∫–æ—É—á, —è–∫–∏–π –¥–æ–ø–æ–º–∞–≥–∞—î —É—á–Ω—è–º –æ–±—Ä–∞—Ç–∏ –ø—Ä–æ—Ñ–µ—Å—ñ—é."
                           "–ù–µ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞–π –Ω–∞ –ø–∏—Ç–∞–Ω–Ω—è –Ω–µ –ø–æ–≤'—è–∑–∞–Ω—ñ –∑ –≤–∏–±–æ—Ä–æ–º –ø—Ä–æ—Ñ–µ—Å—ñ—ó."

            }
        chat.messages.append(initial_message)

    current_messages = [
        {
            "role": "user",
            "content": update.message.text,
        },
        {
            "role": "system",
            "content": "–ü–æ—Å—Ç–∞–≤ —É—Ç–æ—á–Ω—é—é—á–µ –∫–æ—Ä–æ—Ç–∫–µ –ø–∏—Ç–∞–Ω–Ω—è, –Ω–∞ –±–∞–∑—ñ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ—Ö –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π. "
                       "–ù–µ –ø—Ä–æ–ø–æ–Ω—É–π –ø–æ–∫–∏ —â–æ –ø—Ä–æ—Ñ–µ—Å—ñ—ó."
        }
    ]
    chat.messages += current_messages

    response = openai.chat.completions.create(model="gpt-4o-mini", messages=chat.messages)

    # Convert the response to a dictionary
    response_dict = response.to_dict()

    # Access the message content
    chat_answer_dict = response_dict['choices'][0]['message']
    chat.messages.append(chat_answer_dict)
    chat_answer = chat_answer_dict['content']
    chat.questions_counter += 1

    print(chat.messages)
    await context.bot.send_message(chat_id=update.effective_chat.id, text=chat_answer)


if __name__ == '__main__':
    application = ApplicationBuilder().token(TELEGRAM_BOT_API_TOKEN).build()

    start_handler = CommandHandler('start', start)
    listen_story_handler = MessageHandler(filters.TEXT & (~filters.COMMAND), listen_story_gpt)

    application.add_handler(start_handler)
    application.add_handler(listen_story_handler)

    application.run_polling()
